from sr_dataset import SRCNNDataset
from srcnn_model import SRCNN
from torch.utils.data import DataLoader
import torch
import torch.nn as nn
import torch.optim as optim
import time
import os

# --- 1. Parametreler ---
HR_DIR = "hr_images"
LR_DIR = "lr_images"
BATCH_SIZE = 16
NUM_EPOCHS = 100       # Ã–NEMLÄ°: Modelin Ã¶ÄŸrenmesi iÃ§in en az 100 epoch Ã¶nerilir 
LEARNING_RATE = 0.0001 # Daha hassas Ã¶ÄŸrenme iÃ§in hÄ±z dÃ¼ÅŸÃ¼rÃ¼ldÃ¼

# Cihaz SeÃ§imi
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
if torch.cuda.is_available():
    print(f"âœ… GPU AKTÄ°F: {torch.cuda.get_device_name(0)}")
else:
    print("âš ï¸ GPU BULUNAMADI, CPU ile devam ediliyor (YavaÅŸ olabilir)...")

def train_model():
    print("\n--- 1. HazÄ±rlÄ±k AÅŸamasÄ± ---")
    
    # 2. Dataset ve DataLoader
    try:
        train_dataset = SRCNNDataset(
            hr_dir=HR_DIR,
            lr_dir=LR_DIR,
            patch_size=33, # SRCNN orijinal kaÄŸÄ±t deÄŸeri [3]
            scale_factor=4
        )
        
        # num_workers=0: Windows'ta Ã§oklu iÅŸlem hatalarÄ±nÄ± Ã¶nlemek iÃ§in kritiktir.
        train_loader = DataLoader(
            dataset=train_dataset,
            batch_size=BATCH_SIZE,
            shuffle=True,
            num_workers=0,  
            drop_last=True
        )
        print(f"Dataset YÃ¼klendi. Toplam Resim Ã‡ifti: {len(train_dataset)}")
    except Exception as e:
        print(f"âŒ HATA: Dataset yÃ¼klenemedi: {e}")
        return

    # 3. Model, KayÄ±p Fonksiyonu ve Optimizasyon
    model = SRCNN().to(DEVICE)
    
    # MSE Loss: PSNR deÄŸerini doÄŸrudan artÄ±rmayÄ± amaÃ§lar [4, 5]
    criterion = nn.MSELoss() 
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

    print(f"\n--- 2. EÄŸitim BaÅŸlÄ±yor (Hedef: {NUM_EPOCHS} Epoch) ---")
    start_time = time.time()

    for epoch in range(1, NUM_EPOCHS + 1):
        model.train()
        running_loss = 0.0
        
        for i, (lr_patches, hr_patches) in enumerate(train_loader):
            lr_patches = lr_patches.to(DEVICE)
            hr_patches = hr_patches.to(DEVICE)

            # Gradyan sÄ±fÄ±rlama ve Ä°leri besleme
            optimizer.zero_grad()
            sr_output = model(lr_patches)
            
            # KayÄ±p hesaplama ve Geriye yayÄ±lÄ±m
            loss = criterion(sr_output, hr_patches)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

            # Her 20 batch'te bir durum gÃ¶ster
            if i % 20 == 0:
                print(".", end="", flush=True)

        avg_loss = running_loss / len(train_loader)
        
        # Her 10 epoch'ta bir detaylÄ± durum yazdÄ±r
        if epoch % 10 == 0 or epoch == 1:
            elapsed_time = time.time() - start_time
            print(f"\nğŸš€ Epoch | Ortalama KayÄ±p: {avg_loss:.6f} | SÃ¼re: {elapsed_time:.1f}sn")
            
            # Ara aÄŸÄ±rlÄ±klarÄ± kaydet (Ã‡Ã¶kme ihtimaline karÅŸÄ± yedek)
            torch.save(model.state_dict(), "srcnn_checkpoint.pth")

    # 4. Final KayÄ±t
    print("\nğŸ‰ EÄÄ°TÄ°M TAMAMLANDI!")
    torch.save(model.state_dict(), "srcnn_model_weights.pth")
    print(f"Model aÄŸÄ±rlÄ±klarÄ± 'srcnn_model_weights.pth' olarak kaydedildi.")

if __name__ == "__main__":
    train_model()